################################## HTK ########################################

###############################################################################
Aclaraciones:
-------------------------------------------------------------------------------

Cuando se pone el simbolo º, indica una referencia por lo tanto el primer
simbolo sobre un comando indica al ultimo referenciado

###############################################################################
Aclaraciones sobre el uso del servidor:
-------------------------------------------------------------------------------

Para iniciar sesion en el servidor de la facu se usa el comando:

ssh -X -l "usuario" habla.fi.uba.ar

El -X es opcional, pero te permite usar etornos graficos del servidor
 directamente. Recomiendo usarlo.

exit para salir del servidor.

###############################################################################
Comienzo del trabajo de HTK:
###############################################################################

###############################################################################
Creacion de las carpetas:
-------------------------------------------------------------------------------

Se creo la siguiente estructura de carpetas:

* proyecto
   * datos
      * wav (esto se crea cuando realizamos el puntero a wav de la carpeta
              /dbase/latino40/wav)º
         * train
         * test
      * mfc
         * train
         * test
   * etc
   * modelos
   * rec
   * log
   * config
   * scripts
   * lm

Para eso se uso el comando mkdir "nombre de la carpeta" de la terminar
de ubuntu(obs: tambien se puede hacer mkdir "carpeta1" "carpeta2" ..., y poner
una direccion de la carpeta, como "datos/wav", para esto datos tiene que
estar creada ). Para borar una carpeta con sub carpetas adentro uso el comando
rm "nombre de la carpeta" -R (el -R indica que es recursivo).

A continuacion se copiaron los siguientes archivos de la carpeta
/home/cestien/proyecto:

* config.hcopy en ~/proyecto/config
* go.mfclist, prompts2mlf, go.gen-hmmdefs  y go.gen-macros  en ~/proyecto/scripts
* lexicon, lexicon.gf, wlistgf, promptsl40.train, promptsl40.test, mkphones-sp.led  en  ~/proyecto/etc
* proto en ~/proyecto/modelos

Para eso se uso el comando cp "archivo a copiar" "lugar donde copiar".

###############################################################################
Parametrizacion de los datos:
-------------------------------------------------------------------------------

Para comenzar, creo un puntero (un link) que apunte a los datos ubicados en la carpeta
"/dbase/latino40/wav", para eso se utiliza el comando

	ln -s /dbase/latino40/wav

con esto logro conseguir los datos sobre la direccion proyecto/datos/wav. Ahora
genero dos archivos que me tienen listas de las direcciones de los mfc. Estos
archivos se llaman genmfc.train y genmfc.test, estos archivos fueron generados 
a partir del programa copiado de la carpeta de cestine llamado "go.mfclist" ejecutando 
el siguiente comando:

	../scripts/go.mfclist genmfc.train genmfc.test 

genmfc.train y genmfc.test contienen lo siguiente:

Ejemplo genmfc.train:
"wav/train/af01/af01_001.wav" "mfc/train/af01/af01_001.mfc/"
....(continua uno debajo del otro )

Ejemplo genmfc.test:
"wav/test/af14/af14_001.wav" "mfc/test/af14/af14_001.mfc/"
....(continua uno debajo del otro )

Ahi se observa que los archivos contienen solo las direcciones de los datos de
entrenamiento y de testeo, estos archivos se encuentran en la carpeta
proyecto/datos/mfc/. La herramienta de HTK pide tenes estos archivos para
realizar el comando HCopy, este comando me genera los archivos mfcc que seran
utilizado luego. Para configurar el HCopy, uso el archivo
proyecto/config/config.hcopy que contiene lo siguiente

# Coding parameters (T=True F=False)
TARGETKING = MFCC_0
#TARGETKING = MFCC_0_D_A
TARGETRATE = 100000.0
SAVECOMPRESSED = T (¿guardar con compresion?)
SAVEWITHCRC = T
WINDOWSIZE =250000.0 (tamaño de la ventana)
USEHAMMING = T  (si uso la ventana de hamming)
PREEMCOEF = 0.97
NUMCHANS =26
CEPLIFTER = 22
NUMCEPS =12
ENORMALISE = F (normalizar los datos)
SOURCEFORMAT = NIST (formato)

El comando HCopy -A -V -T 1 -C proyecto/config/config.hcopy -S  proyecto/datos/genmfc.train y el comando
HCopy -A -V -T 1 -C proyecto/config/config.hcopy -S proyecto/datos/genmfc.test me carga la confiuracion
del archivo config.hcopy. Aparte me genero los archivos af14_001.mfc en la carpeta proyecto/datos/mfc/af14.
Y asi con cada unos de los datos de entrenamiento o testeo, para eso ejecuto el programa go.mfclist copiado
de la carpeta de cestien.

###############################################################################
Creación de un diccionario:
-------------------------------------------------------------------------------

Para realizar un reconecedor de voz, necesito un listado de pronunciaciones que quiero reconocer. A este 
listado lo llamamos diccionario.
El diccionario se puede crear con la herramienta HDMan, pero esta herramienta pides unos archivos en cierto formato,
para eso me genero una lista de palabras (antes tengo que tener activado el LC_CTYPE=ISO_8859_1)
para despues crear un diccionario de palabras junto con un archivo que contiene los fonemas con el
comando de HDMan. Las palabras usada, son las palabras que se encuentran en los datos de entrenamiento como de testeo 
esto se debe porque lo que el diccionario tiene que contener las palabras que uno quiere estimar, y para realizar el 
testeo necesito que el diccionaria tenga las palabras de testeo (aunque estas no aparezcan en el entrenamiento). Si una
palabra no esta en el diccionario, lo que ocurre que el reconocedor inteta estimarla con una palabra que se encuentre en 
el mismo (no estoy seguro de esto ultimo, porque en realidad hacemos un entrenamiento de fonemas).
Para eso ejecuto el comando:

cat /proyecto/etc/promptsl40.train /proyecto/etc/promptsl40.test | awk \
    '{for(i=2;i<NF;i++){print $i}}' | sort | uniq > /proyecto/etc/wlistl40

Donde se me genera un archivo de wlistl40 que contiene una lista de palabras de cada palabra de los datos(entrenamiento y testeo). De
la siguiente forma:

a
abajo
abandona
...(continua para abajo en orden alfabetico, esto es por el sort y el uniq saca las repeticiones)

Una vez obtenida la lista, se prosigue a la creacion del diccionario con el HDMan mencionado anteriormente.
Se crea un archivo /proyecto/etc/global.ded con la siguiente instruccion:

  echo "AS sp" > /proyecto/etc/global.ded (agrega un fonema de short pausa al final de cada palabra)

Luego se prosigue a realizar el HDMan con la siguiente linea (mantener activado el LC_CTYPE=ISO_8859_1):

  HDMan -m -/proyecto/etc/wlist40 -g /proyecto/etc/global.ded -n monophones+sil -l \
          proyecto/log/hdman.log /proyecto/etc/dictl40 /proyecto/etc/lexicon

Me devuelve el diccionario en el archivo dictl40 y el archivo monophones+sil que se encuentra los diferentes fonemas,
este archivo se edita y se agrega el fonema sil y se borra el fonema sp (sil me indica el fin/comienzo de cada palabra y el sp 
es un fonome que se agrega de paso, pero para mejorar el reconocimiento se entrena mas adelante). El archivo dictl40 tiene la 
siguiente forma:

	<palabra1> <fonema1> <fonema2> <fonema3> ... sp(por el AS sp) [fonema1 es el primer fonema y asi con todas las demas]
	<palabra2> <fonema1> <fonema2> <fonema3> ... sp(por el AS sp)
	(con todas las palabras del listado wlistl40)

y el monophones+sil:
	
	<fonema1>
	<fonema2>
	<fonema3>
	...(con todos los fonomelas el listado wlistl40 )

###############################################################################
Creacion de las transcripciones de palabra y fonética:
-------------------------------------------------------------------------------

A continuacion, proseguimos a realizar los archivos master label file o MLF (se explica mas abajo). Se uso el programa prompts2mlf
que transforma las transcripciones promptsl40.train y promptsl40.test en archivos MLF. Se ejecuto de la forma:

  proyecto/scripts/prompts2mlf trainmlf promptsl40.train
  proyecto/scripts/prompts2mlf testmlf promptsl40.test

Se continua creando las transcripciones de estos fonemas con la herramienta HLEd, para eso se necesita un archivo
mkphones0.led, en el cual tiene las siguientes instrucciones:

  EX            (reemplaza las palabras por su pronunciacion en el diccionario)
  IS sil sil    (inserta silencios al principio y al final de cad audio)
  DE sp         (borrar los sp de los audios)

Luego desactivo el LC_CTYPE=ISO_8859_1 con el comando "unset LC_CTYPE" y prosigo en ejecutar el comando HLEd
de la siguiente forma:

  HLED -l '*' -d dictl40 -i phones0.mlf mkphones0.led trainmlf

Este comando me devuelve el archivo phones0.led, que son los datos pero en formato de MLF. Los archivos MLF dan informacion sobre 
las transcripciones, estos pueden a nivel palabra o fonema. El formato que tienen es el siguiente:

	<Nombre del archivo>
	<palabra1/fonema1>
	<palabra2/fonema2>
	...(todas las palabras/fonemas del archivo)
	. (indica el fin del archivo)

los archivos MLF de palabras son los creados con la herramienta prompts2mlf (testmlf y trainmlf), los archivos MLF de los fonemas se uso 
el comando HLED y estan en el archivo phones0.mlf (este no contiene el sp, mas adelante se agrega el sp haciendo lo mismo solo cambiando
la configuracion de mkphones0.led).

###############################################################################
Creacion de modelos de una sola gaussiana:
-------------------------------------------------------------------------------

ACLARACION: en esta seccion se crean tantos directorios que sean necesario para los diferentes modelos, estos llevan el nombre
hmmX, donde X es un numero que va del 0 a 6. Para la mezcla de gaussiana se crean con el siguiente formato hmmX-Y con X es el modelos
y Y es la cantidad de gaussianas.

A continuacion se crea un modelo inical de un modelo HMM (high markov modal), el modelo inicial consiste en los parametros iniciales
usados para la estimacion a través de distribuciones que se pueden generar como una mezcla de gaussiana. Considerando a cada clase como
una sola gaussiana y a través de las herramientas copiadas en la carpeta de cestien, me genero una lista de todos los 
datos de entrenamiento (lo hago con testeo que se usan mas adelante), 

  ls proyectos/datos/mfc/train/*/*  > proyectos/modelos/train.scp
  ls proyectos/datos/mfc/test/*/*  > proyectos/modelos/test.scp

Con los train.scp se calcula una media y una varianza global seteando todas las gaussianas generadas a esa media y varianza.
Cada uno de los HMM tiene un vector de longitud 39 dado que tiene los coeficientes mfc, las diferencias entre ellos y las diferencias
segundas. Para eso se usa el comando HCompV de la siguiente forma:

  HCompV -C proyectos/config -f 0.01 -m -S train.scp -M hmm0 proyecto/modelos/hmm0 proto

Con el comando anterior, se genero 2 archivos. El primero es un piso para la varianza (para evitar que la matriz de cova se haga 
singular)llamado "vFloors" y el segundo llamado proto que es un modelo prototipo de los HMM, donde realiza la media de todos los datos y 
los mismo con la varianza. Usando los programas "go.gen-hmmdefs" y "go.gen-macros" genero los archivos "hmmdefs" y "macros" en las 
carpetas macros y hmmdefs. Los comandos de los programas son los siguietes:

	proyecto/scripts/go.gen-hmmdefs proyecto/etc/monophones+sil proyecto/hmm0/proto > proyecto/hmm0/hmmdefs
	proyecto/scripts/go.gen-macros proyecto/hmm0/vFloors  proyecto/hmm0/proto > proyecto/hmm0/macros

Luego de tener un modelo inical o HMM0, se prosigue a un entrenamiento o una re-estimacion con los datos test.scp y me genero un nuevo 
modelo HMM1 a traves del comando HRest(se realiza hasta un hmm2). El HERest realiza un entrenamiento EM para calcular los parametros de
cada una de las clases, recibe un modelo como datos de entrada y entrega un modelo re estimado como se menciono anteriormente,el HERest
se realiza de la siguiente forma (el comando se realizo en la carpeta proyecto/modelos):

	HERest -C ../config/config -I ../etc/phones0.mlf -t 250.0 150.0 1000.0 -S train.scp -H hmm0/macros\
	       -H hmm0/hmmdefs -M  hmm1 ../etc/monophones+sil (hmm0 es la entreda y la salida es hmm1)
	HERest -C ../config/config -I ../etc/phones0.mlf -t 250.0 150.0 1000.0 -S train.scp -H hmm1/macros\
	       -H hmm1/hmmdefs -M  hmm2 ../etc/monophones+sil (hmm1 es la entreda y la salida es hmm2)

Estos entrenamientos usaron los archivos MLF de los fonemas (sin sp) "phones0.mlf" junto con la lista de los datos de entrenamiento, el 
HERest realiza una re-estimacion de los parametros (media, varianza y matrix de transicion) sobre cada gaussiana de cada clase usando 
la lista de datos de entrenamiento train.scp. El comando tamb ien recibe el archivo "monophones+sil" que es la lista de los fonemas que 
se encuentrar en los datos de entrenamiento.
Pero este entrenamiento no tuvo en cuenta el fonema de sp, por lo tanto se copia los archivos generados a un hmm3 y se edita el modelo 
para incluir el fonema sp. Se tomaron los siguiente valores:

~h "sp"
<BEGINHMM>
  <NUMSTATES> 3
  <STATE> 2
  <MEAN> 39
  	la media del estado 3 del fonema sil
  <VARIANCE> 39
  	la varianza del estado 3 del fonema sil
  <GCONST> 1.017977e+02
  <TRANSP> 3
  0.000000e+00 1.000000e+00 0.000000e+00
  0.000000e+00 9.452302e-01 5.476980e-02
  0.000000e+00 0.000000e+00 0.000000e+00
<ENDHMM>
 

Para continuar con los entrenamientos se utiliza la herramiento HHEd, para eso se usa el archivo sil.hed que contiene lo siguiente:

	AT 2 4 0.2 {sil.transP}
	AT 4 2 0.2 {sil.transP}
	AT 1 3 0.3 {sp.transP}
	TI silst {sil.state[3],sp.state[2]}

donde el comando AT me agrega transiciones a las matrices de transiciones de cada fonema(no entoy seguro de esto me suena raro que lo 
agregue a todos los fonemas.), esto se hace para agregar el silencio sp que no se tuvo encuenta, por otro lado el comando TI me genera
un "tied-state" llamado silst(los parametros de este estado se encuentran en hmmdefs). Todo lo anterior se agrega a través de la
herramienta HTK HHEd que se ejecuta como:

	HHEd -H hmm3/macros -H hmm3/hmmdefs -M hmm4 sil.hed ../etc/monophones+sil+sp

Luego se realizan otros dos entrenamientos con la herramienta HERest (se entrena el fonema sp), y para eso necesito crear un archivo
phones1.mlf que contenga el fonema sp (se hace el mismo HLEd solo que el archivo mkphones0.mlf se le saca la linea DE sp) y se agrega 
en monophones+sil el fonema sp y se renombra con monophones+sil+sp:

  HERest -C ../config/config -I ../etc/phones1.mlf -t 250.0 150.0 1000.0 -S train.scp -H hmm5/macros -H hmm5/hmmdefs\
         -M  hmm5 ../etc/monophones+sil+sp
  HERest -C ../config/config -I ../etc/phones1.mlf -t 250.0 150.0 1000.0 -S train.scp -H hmm6/macros -H hmm6/hmmdefs\
         -M  hmm6 ../etc/monophones+sil+sp

Hasta aca tengo el entrenamiento de una sola gaussiana, a continuacion se prosigue a realizar el algoritmo de viterbi para el reconocimiento.

###############################################################################
Creacion de modelos de lenguajes:
-------------------------------------------------------------------------------

Aclaracion:  aca escribi frase o fonema/palabra, pero en realidad el modelo se puede aplicar para cualquiera de los tres,
es decir, puedo tener un modelo de frase o de palabra o de fonema no es que una probabilidad depende de eso o sea que sea
solo de la frase o palabra o fonema sino que puede ser cualquiera de los 3. (Esto hay una probabilidad que no estoy seguro
que dice asi P(Y|W), creo que la Y es lo anterior a W o algo asi, porque no me cierra, y a anterior me refiero si W es 
palabra, Y es tal fonema).).

Un modelo de lenguaje usa una aproximacion de N-gramas, el modelo es la probabilidad de que la persona dijo esa frase para eso se aproxima a 
N-gramas (la palabra dicha depende solo de las N palabras anteriores). Para el calculo de esta probabilidad se usa un conteo sobre los datos
de entrenamiento ( la probabilidad de una palabra es la cantidad de veces que se dijo esa palabras sobre las palabras totales. Si se usa laplace
se tiene que se suma uno al numerador pero eso cambia al denominador y termina siendo la suma de todas las frases o datos que se dijo esa palabra.)
En realidad, el modelo es el argumento maximo (esto es por la estimacion de la frase, busco la frase de mayor probabilidad)
del producto de una probabilidad de cada uno de los fonemas/palabras con la probabilidad de cada fonema/palabra.

Para la creacion de los modelos, necesito las transcripciones sin la identificacion que se coloca en "promptsl40.train". Para eso
se usa el awk de nuevo, y guardando el resultado en train.txt:

  awk '{for(n=2;n<=NF;n++){printf"%s ",$n;}printf"\n";}' promptsl40.train > train.txt

(La verdad supongo que se usan los datos de train para no mezclar con los datos de testeo, pero no se porque usamos los de test, se que estan las
 transcripciones ahi).Luego me genero el vocabulario usando los datos de testeo:

  cat promptsl40.test |awk '{for(i=2;i<=NF;i++){print $i}}'|sort|uniq > vocab

El vocabulario contiene una lista de palabras que quiero detectar, pero tenemos que suponer que queremos detectar esas palabras.
El vocabulario no tiene los estados de <s> y </s> (son estado no?, fonema pensandolo bien no pueden ser, me suenan que son estados
para el hmm indicando el fin de cada palabra/fonema) por lo que se agrega editando vocab. Esto se hace para poder detectar los
comienzo y fines de cada frase/palabra/fonema. Lo mismo se hace con el diccionario agregando lo siguiente:

  <s>  [] sil
  </s> [] sil

Usando la herramienta SRIML "ngram-count" se crea un modelo de lenguaje llamado "lml40", generando bigramas (dos palabras), 
se ejecuto el siguiente comando(en la carpeta proyecto/modelos):

  ../../../../usr/local/speechapp/srilm/bin/i686-m64/ngram-count -order 2 -text train.txt -lm lml40 -ukndiscount2 -vocab vocab

 la propiedad -orden me dice el maximo orden de ngramas, mientras ukndiscount2 indica que se usa un suaviza de tipo Kneser-Ney. Esto me
 genera el lml40. Luego se crea una red de palabras o lattice, para eso el HTK tiene la herramienta de HBuild y necesita el modelo de bigramas
 y el vocabulario (vocab). El comando a ejecutar es el siguiente:

  HBuild -s '<s>' '</s>' -n lml40  vocab wdnet

donde el -s indica el comienzo y el fin de cada frase (por eso hay que agregarlo al vocabulario). Con esto obtego el wdnet para despues usar 
para el reconocimiento de las palabras de testeo. El wdnet es una lista de palabras que de entrada al modelo del lenguaje.

###############################################################################
Reconocimiento con el modelo de unigramas y una sola gaussiana:
-------------------------------------------------------------------------------

Luego de tener el wdnet, el HTK nos da una herramienta para la implementacion del algoritmo de viterbi (reconocimiento) y la herramienta
HResults para la evaluacion de los resultados. Nos paramos en la carpeta proyecto/rec y ejecutamos el algoritmo de viterbi con el siguiente
comando:

  HVite -H -C ../config/config ../modelos/hmm6/macros -H ../modelos/hmm6/hmmdefs -S ../modelos/test.scp -l '*'\
	      -i ../etc/recout.mlf -w ../etc/wdnet -p 0.0 -s 5.0 ../etc/dictl40 ../etc/monophones+sil+sp &

El comando de HVite realiza el algoritmo de viterbi busca el recorrido de maxima probabilidad del modelo hmm6 para estimar los datos que se
encuentra en test.scp, y devuelve un archivo MLF llamado recout, para calcular estas probabilidades se necesita el diccionario, las palabras
que quiero estimar y la lista de fonemas.Observamos los resultados con el siguiente comando(los resultados se encuentra en el archivo 
recount.mlf):

  HResults -I test.mlf monophones+sil+sp recout.mlf

dando lo siguiente:

====================== HTK Results Analysis =======================
  Date: Tue Dec 10 17:34:07 2019
  Ref : ../etc/testmlf
  Rec : recout.mlf
------------------------ Overall Results --------------------------
SENT: %Correct=8.00 [H=79, S=908, N=987]
WORD: %Corr=59.58, Acc=46.54 [H=4713, D=395, S=2802, I=1032, N=7910]
===================================================================

Es un 60%, para la mejora de este porcentaje se usan las mezclas de gaussianas esplicado mas adelante.

###############################################################################
Refinamiento del modelo agregando mezclas de gaussianas:
-------------------------------------------------------------------------------

Los resultados anteriores fueron con una sola gaussiana, a continuacion se entrena una mezcla de gaussiana. Para eso se creo el archivo 
"cmds.hed", que contine la linea "MU 2 {*.state[2-17].mix}" que decide cuantas gaussianas crear (el numero 2 dice la cantidad). Luego se 
usa el HHEd para crear un modelo HMM1-2 a partir del modelo anterior, en este caso el modelo de una gaussiana de hmm6:

	HHEd -H hmm6/macros -H hmm6/hmmdefs -M hmm1-2 cmds.hed ../etc/monophones+sil+sp

Se realiza dos entrenamiento mas con lo visto anteriormente (HRest) y luego se corre el HVite para el reconocimiento. Se observan los 
resultados con HResults con el archivo recoutX.mlf (la X indica la cantidad de gaussianas). Esto se hace con mezclas de gaussianas de 
2,4,8,16,32,64,128 y 256 siempre usando la ultima mezcla de gaussiana usada, es decir para la mezcla de 16 gaussianas primero se entreno 
la mezcla de 8 gaussiana y despues se uso el HHEd cambiando el cmds.hed para que cree la mezcla de 16 gaussianas. Se muestras los resultados:

Aclaracion: aca cuando se termino de entrenar un modelo, por ejemplo, hmm3-2, se uso este ultimo modelo para la creacion del modelo hmm3-4 usando
el HHEd (la entrada es hmm3-2 y la salida hmm1-4). Luego lo mismo para cada gaussiana, al final se tienen 6 modelos para una gaussiana sola (hmm1,
hmm2,hmm3,hmm4,hmm5 y hmm6) y 3 modelos paras las mezclas de gaussianas (hmm1-X,hmm2-X y hmm3-X, donde X es la cantidad que pertenece al siguiente 
conjunto de numeros: 2,4,8,16,32,64,128 y 256)

2 gaussianas:
====================== HTK Results Analysis =======================
  Date: Tue Dec 10 17:34:12 2019
  Ref : ../etc/testmlf
  Rec : recout2.mlf
------------------------ Overall Results --------------------------
SENT: %Correct=12.66 [H=125, S=862, N=987]
WORD: %Corr=65.18, Acc=54.12 [H=5156, D=363, S=2391, I=875, N=7910]
===================================================================
4 gaussianas:
====================== HTK Results Analysis =======================
  Date: Tue Dec 10 17:34:14 2019
  Ref : ../etc/testmlf
  Rec : recout4.mlf
------------------------ Overall Results --------------------------
SENT: %Correct=23.51 [H=232, S=755, N=987]
WORD: %Corr=72.44, Acc=64.87 [H=5730, D=302, S=1878, I=599, N=7910]
===================================================================
8 gaussianas:
====================== HTK Results Analysis =======================
  Date: Tue Dec 10 17:34:17 2019
  Ref : ../etc/testmlf
  Rec : recout8.mlf
------------------------ Overall Results --------------------------
SENT: %Correct=30.29 [H=299, S=688, N=987]
WORD: %Corr=77.33, Acc=70.80 [H=6117, D=274, S=1519, I=517, N=7910]
===================================================================
16 gaussianas:
====================== HTK Results Analysis =======================
  Date: Tue Dec 10 17:34:21 2019
  Ref : ../etc/testmlf
  Rec : recout16.mlf
------------------------ Overall Results --------------------------
SENT: %Correct=35.66 [H=352, S=635, N=987]
WORD: %Corr=80.54, Acc=75.31 [H=6371, D=268, S=1271, I=414, N=7910]
===================================================================
32 gaussianas:
====================== HTK Results Analysis =======================
  Date: Tue Dec 10 17:34:24 2019
  Ref : ../etc/testmlf
  Rec : recout32.mlf
------------------------ Overall Results --------------------------
SENT: %Correct=41.64 [H=411, S=576, N=987]
WORD: %Corr=83.15, Acc=79.30 [H=6577, D=223, S=1110, I=304, N=7910]
===================================================================
64 gaussianas:
====================== HTK Results Analysis =======================
  Date: Tue Dec 10 17:34:35 2019
  Ref : ../etc/testmlf
  Rec : recout64.mlf
------------------------ Overall Results --------------------------
SENT: %Correct=45.39 [H=448, S=539, N=987]
WORD: %Corr=84.69, Acc=81.21 [H=6699, D=207, S=1004, I=275, N=7910]
===================================================================
128 gaussianas:
====================== HTK Results Analysis =======================
  Date: Tue Dec 10 17:34:39 2019
  Ref : ../etc/testmlf
  Rec : recout128.mlf
------------------------ Overall Results --------------------------
SENT: %Correct=46.10 [H=455, S=532, N=987]
WORD: %Corr=85.44, Acc=81.64 [H=6758, D=202, S=950, I=300, N=7910]
===================================================================
256 gaussianas:
====================== HTK Results Analysis =======================
  Date: Tue Dec 10 17:34:44 2019
  Ref : ../etc/testmlf
  Rec : recout256.mlf
------------------------ Overall Results --------------------------
SENT: %Correct=46.10 [H=455, S=532, N=987]
WORD: %Corr=85.11, Acc=80.52 [H=6732, D=172, S=1006, I=363, N=7910]
===================================================================

De aca se ve que usar 258 es un gasto de computadora inecesario, porque baja el reconocimiento
entonces conviene usar 128. Hay que aclarar que esto es para la cantidad de datos usados.

UNA PREGUNTA: se que se usan los coeficientes mfcc para el reconocimiento que divide por bandas
la señal de audio y es mas compatible con la respuesta del oido (cambia la amplitud por bandas,
segun entendi). Pero entre el cepstrum y LPC, lo que veo es que son dos formas para transmitir o 
representar los datos solo que en el LPC te quedas con la ganancia y la matriz A y el cepstrum los
coeficientes cepstrum ¿porque se usa cepstrum en lugar de LPC?. Talvés entendi mal los temas.